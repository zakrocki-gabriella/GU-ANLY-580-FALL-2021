{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-05: Visualizing tweets from the 2020 US presidential election"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Dataset is a randomly sampled subset of: https://www.kaggle.com/manchunhui/us-election-2020-tweets\n",
    "trump = pd.read_csv(\"2020_tweets_trump.csv\", lineterminator='\\n')\n",
    "biden = pd.read_csv(\"2020_tweets_biden.csv\", lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biden), len(trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10000\n",
    "trump = trump.sample(n=M//2)\n",
    "biden = biden.sample(n=M//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_tweets = biden['tweet'].tolist()\n",
    "trump_tweets = trump['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'People rejoicing #Biden win must remember he can very well restart WHO funding, he can start pak funding, reinstate relationship with China. So much for #humanity. Do remember!!!! THESE ARE FEW NEGATIVES AS I SEE.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_tweets[3023]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "pipeline_name = '2020ElectionTweets'\n",
    "\n",
    "\n",
    "def camel_case_split(str):\n",
    "    \"\"\" This function turns in #Biden2020 into Biden 2020 \"\"\"\n",
    "    return \" \".join([wrd for wrd in re.findall(r'[A-Z](?:[a-z]+|[A-Z]*(?=[A-Z]|$))', str)])\n",
    "\n",
    "\n",
    "@Language.component(pipeline_name)\n",
    "def preprocess(doc):\n",
    "    doc = [token for token in doc if not token.is_punct]\n",
    "    # doc = [token for token in doc if not token.is_stop]\n",
    "    doc = [token.text.lower().strip() for token in doc]\n",
    "    doc = [token for token in doc if 0 < len(token) <= 12]\n",
    "    return \" \".join(doc)\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    \n",
    "    # http://emailregex.com/\n",
    "    email_re = r\"\"\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)\n",
    "    *|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]\n",
    "    |\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9]\n",
    "    (?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}\n",
    "    (?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?|[a-z0-9-]*[a-z0-9]:\n",
    "    (?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\"\"\"\n",
    "    # replace = [ (pattern-to-replace, replacement),  ...]\n",
    "    replace = [\n",
    "        (\"<[^>]*>\", \" \"),\n",
    "        (email_re, \" \"),                           # Matches emails\n",
    "        (r\"(?<=\\d),(?=\\d)\", \"\"),                   # Remove commas in numbers\n",
    "        (r\"\\d+\", \" \"),                             # Map digits to special token <numbr>\n",
    "        (r\"[*\\^\\.$&@<>,\\-/+{|}=?#:;'\\\"\\[\\]]\", \"\"), # Punctuation and other junk\n",
    "        (r\"[\\n\\t\\r]\", \" \"),                        # Removes newlines, tabs, creturn\n",
    "        (r\"[^\\x00-\\x7F]+\", \"\"),                    # Removes non-ascii chars\n",
    "        (r\"\\\\+\", \" \"),                             # Removes double-backslashs\n",
    "        (r\"\\s+n\\s+\", \" \"),                         # 'n' leftover from \\\\n\n",
    "        (r\"\\s+\", \" \")                              # Strips extra whitespace\n",
    "    ]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pipeline = spacy.load('en_core_web_sm')\n",
    "        self.pipeline.add_pipe(pipeline_name);\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.transform(*args, **kwargs)\n",
    "\n",
    "    def transform(self, doc: str):\n",
    "        for repl in self.replace:\n",
    "            doc = re.sub(repl[0], repl[1], doc)\n",
    "        doc = camel_case_split(doc)\n",
    "        return self.pipeline(doc)\n",
    "    \n",
    "pipeline = Pipeline();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with tqdm(total=M//2) as bar:\n",
    "    for i, (bt, tt) in enumerate(zip(biden_tweets, trump_tweets)):\n",
    "        biden_tweets[i] = pipeline(bt)\n",
    "        trump_tweets[i] = pipeline(tt)\n",
    "        bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_tweets[3023]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate documents for vocab generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = biden_tweets + trump_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (20 pts) Task I: Train a Doc2Vec model (using the Gensim package) on tweets from the 2020 US presidential election\n",
    "\n",
    "*Docs*: \n",
    "\n",
    "* https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "\n",
    "*Useful tutorials*: \n",
    "\n",
    "* https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial \n",
    "* https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change as needed\n",
    "K = 20\n",
    "word_frequency_threshold = 2\n",
    "epochs = 10\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model = Doc2Vec(vector_size=K, min_count=word_frequency_threshold, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (10  pts) Task II: Evaluate your model by computing the most similar documents (tweets) to new (perhaps made up) tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template function\n",
    "def find_similar_tweets(tweet, top_n=10):\n",
    "    doc_vector = model.infer_vector(tweet)\n",
    "    sims = model.dv.most_similar([doc_vector], topn=top_n)\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (10 pts extra credit) Task III: Produce a scatter plot of the compressed document embeddings (2D or 3D)\n",
    "\n",
    "*Useful resources*:\n",
    "\n",
    "* http://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
